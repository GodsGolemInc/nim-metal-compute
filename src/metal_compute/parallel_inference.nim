## Parallel Inference Engine
## ãƒ­ãƒƒã‚¯ãƒ•ãƒªãƒ¼ãƒ»ã‚¹ãƒ¬ãƒƒãƒ‰ä¸¦åˆ—æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³
##
## ç‰¹å¾´:
## - å®Œå…¨ãªçŠ¶æ…‹åˆ†é›¢ï¼ˆå„ã‚¹ãƒ¬ãƒƒãƒ‰ãŒç‹¬è‡ªã®ExtremeEngineã‚’æ‰€æœ‰ï¼‰
## - False Sharingé˜²æ­¢ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ©ã‚¤ãƒ³å¢ƒç•Œãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
## - äº‹å‰ãƒãƒƒãƒ•ã‚¡ç¢ºä¿ï¼ˆãƒ¡ãƒ¢ãƒªç¢ºä¿ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰å‰Šæ¸›ï¼‰
## - 2000ä¸‡+ samples/secï¼ˆ8ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰

import std/[cpuinfo, times, monotimes, strformat]
import ./extreme_inference

const
  MaxThreads* = 16
  CacheLinePadding = 128
  DefaultBufferSize* = 1_000_000

type
  ## ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ä»˜ããƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆFalse Sharingé˜²æ­¢ï¼‰
  PaddedWorker = object
    engine: ExtremeEngine
    inputBuf: ptr UncheckedArray[array[InputSize, float32]]
    outputBuf: ptr UncheckedArray[int]
    confBuf: ptr UncheckedArray[float32]
    startIdx: int
    endIdx: int
    pad: array[CacheLinePadding, byte]

  ## ä¸¦åˆ—æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³
  ParallelInferenceEngine* = object
    numThreads*: int
    workers: array[MaxThreads, PaddedWorker]
    threads: array[MaxThreads, Thread[ptr PaddedWorker]]
    initialized: bool
    # äº‹å‰ç¢ºä¿ãƒãƒƒãƒ•ã‚¡
    outputBuffer*: seq[int]
    confBuffer*: seq[float32]
    bufferSize*: int

  ## ãƒãƒƒãƒæ¨è«–çµæœ
  BatchInferenceResult* = object
    categories*: seq[int]
    confidences*: seq[float32]
    count*: int
    elapsedNs*: int64
    throughput*: float  # samples/sec

{.push checks:off, boundChecks:off.}

proc workerProcFast(data: ptr PaddedWorker) {.thread.} =
  ## ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ - ã‚«ãƒ†ã‚´ãƒªã®ã¿ï¼ˆæœ€é€Ÿç‰ˆï¼‰
  for i in data.startIdx ..< data.endIdx:
    data.outputBuf[i] = data.engine.inferExtreme(addr data.inputBuf[i])

proc workerProcFull(data: ptr PaddedWorker) {.thread.} =
  ## ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ - ä¿¡é ¼åº¦ä»˜ã
  for i in data.startIdx ..< data.endIdx:
    let (cat, conf) = data.engine.inferExtremeWithConf(addr data.inputBuf[i])
    data.outputBuf[i] = cat
    data.confBuf[i] = conf

{.pop.}

proc initParallelEngine*(engine: var ParallelInferenceEngine,
                          numThreads: int = 0,
                          bufferSize: int = DefaultBufferSize) =
  ## ä¸¦åˆ—æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–
  engine.numThreads = if numThreads == 0: countProcessors() else: min(numThreads, MaxThreads)

  # äº‹å‰ãƒãƒƒãƒ•ã‚¡ç¢ºä¿
  engine.bufferSize = bufferSize
  engine.outputBuffer = newSeq[int](bufferSize)
  engine.confBuffer = newSeq[float32](bufferSize)

  # å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–
  for i in 0 ..< engine.numThreads:
    engine.workers[i].engine.initWeights(uint32(42 + i))

  engine.initialized = true

proc syncWeights*(engine: var ParallelInferenceEngine,
                  weightsIH: ptr array[InputSize, array[HiddenSize, float]],
                  biasH: ptr array[HiddenSize, float],
                  weightsHO: ptr array[HiddenSize, array[OutputSize, float]],
                  biasO: ptr array[OutputSize, float]) =
  ## å…¨ãƒ¯ãƒ¼ã‚«ãƒ¼ã®é‡ã¿ã‚’åŒæœŸ
  for i in 0 ..< engine.numThreads:
    engine.workers[i].engine.setWeights(weightsIH, biasH, weightsHO, biasO)

proc inferBatchParallelFast*(engine: var ParallelInferenceEngine,
                              inputs: ptr UncheckedArray[array[InputSize, float32]],
                              outputs: ptr UncheckedArray[int],
                              count: int) =
  ## ãƒãƒƒãƒæ¨è«–ã‚’ä¸¦åˆ—å®Ÿè¡Œï¼ˆã‚«ãƒ†ã‚´ãƒªã®ã¿ã€æœ€é€Ÿç‰ˆï¼‰
  if count == 0:
    return

  let batchPerThread = (count + engine.numThreads - 1) div engine.numThreads

  # å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ç¯„å›²ã‚’å‰²ã‚Šå½“ã¦
  for i in 0 ..< engine.numThreads:
    engine.workers[i].inputBuf = inputs
    engine.workers[i].outputBuf = outputs
    engine.workers[i].startIdx = i * batchPerThread
    engine.workers[i].endIdx = min((i + 1) * batchPerThread, count)

  # ã‚¹ãƒ¬ãƒƒãƒ‰èµ·å‹•
  for i in 0 ..< engine.numThreads:
    if engine.workers[i].startIdx < engine.workers[i].endIdx:
      createThread(engine.threads[i], workerProcFast, addr engine.workers[i])

  # å…¨ã‚¹ãƒ¬ãƒƒãƒ‰å®Œäº†å¾…ã¡
  for i in 0 ..< engine.numThreads:
    if engine.workers[i].startIdx < engine.workers[i].endIdx:
      joinThread(engine.threads[i])

proc inferBatchParallel*(engine: var ParallelInferenceEngine,
                          inputs: ptr UncheckedArray[array[InputSize, float32]],
                          outputs: ptr UncheckedArray[int],
                          confidences: ptr UncheckedArray[float32],
                          count: int) =
  ## ãƒãƒƒãƒæ¨è«–ã‚’ä¸¦åˆ—å®Ÿè¡Œï¼ˆä¿¡é ¼åº¦ä»˜ãï¼‰
  if count == 0:
    return

  let batchPerThread = (count + engine.numThreads - 1) div engine.numThreads

  for i in 0 ..< engine.numThreads:
    engine.workers[i].inputBuf = inputs
    engine.workers[i].outputBuf = outputs
    engine.workers[i].confBuf = confidences
    engine.workers[i].startIdx = i * batchPerThread
    engine.workers[i].endIdx = min((i + 1) * batchPerThread, count)

  for i in 0 ..< engine.numThreads:
    if engine.workers[i].startIdx < engine.workers[i].endIdx:
      createThread(engine.threads[i], workerProcFull, addr engine.workers[i])

  for i in 0 ..< engine.numThreads:
    if engine.workers[i].startIdx < engine.workers[i].endIdx:
      joinThread(engine.threads[i])

proc inferBatchFastDirect*(engine: var ParallelInferenceEngine,
                            inputs: ptr UncheckedArray[array[InputSize, float32]],
                            count: int): ptr UncheckedArray[int] =
  ## ç›´æ¥ãƒãƒƒãƒ•ã‚¡ã‚¢ã‚¯ã‚»ã‚¹ç‰ˆï¼ˆã‚³ãƒ”ãƒ¼ãªã—ã€æœ€é€Ÿï¼‰
  ## æˆ»ã‚Šå€¤ã¯å†…éƒ¨ãƒãƒƒãƒ•ã‚¡ã¸ã®ãƒã‚¤ãƒ³ã‚¿ï¼ˆæ¬¡å›å‘¼ã³å‡ºã—ã¾ã§æœ‰åŠ¹ï¼‰
  if count > engine.bufferSize:
    engine.bufferSize = count
    engine.outputBuffer = newSeq[int](count)

  engine.inferBatchParallelFast(
    inputs,
    cast[ptr UncheckedArray[int]](addr engine.outputBuffer[0]),
    count
  )

  result = cast[ptr UncheckedArray[int]](addr engine.outputBuffer[0])

proc inferBatchFast*(engine: var ParallelInferenceEngine,
                      inputs: seq[array[InputSize, float32]]): BatchInferenceResult =
  ## seqç‰ˆãƒãƒƒãƒæ¨è«–ï¼ˆã‚«ãƒ†ã‚´ãƒªã®ã¿ï¼‰
  let count = inputs.len
  if count == 0:
    return BatchInferenceResult(count: 0)

  if count > engine.bufferSize:
    engine.bufferSize = count
    engine.outputBuffer = newSeq[int](count)

  result.count = count

  let start = getMonoTime()

  engine.inferBatchParallelFast(
    cast[ptr UncheckedArray[array[InputSize, float32]]](unsafeAddr inputs[0]),
    cast[ptr UncheckedArray[int]](addr engine.outputBuffer[0]),
    count
  )

  result.elapsedNs = (getMonoTime() - start).inNanoseconds
  result.throughput = count.float / (result.elapsedNs.float / 1e9)

  # shallowCopyç›¸å½“ï¼ˆNimã®seqã‚¹ãƒ©ã‚¤ã‚¹ã¯å‚ç…§ã‚«ã‚¦ãƒ³ãƒˆå…±æœ‰ï¼‰
  result.categories = engine.outputBuffer[0..<count]

proc inferBatch*(engine: var ParallelInferenceEngine,
                  inputs: seq[array[InputSize, float32]]): BatchInferenceResult =
  ## seqç‰ˆãƒãƒƒãƒæ¨è«–ï¼ˆä¿¡é ¼åº¦ä»˜ãï¼‰
  let count = inputs.len
  if count == 0:
    return BatchInferenceResult(count: 0)

  if count > engine.bufferSize:
    engine.bufferSize = count
    engine.outputBuffer = newSeq[int](count)
    engine.confBuffer = newSeq[float32](count)

  result.count = count

  let start = getMonoTime()

  engine.inferBatchParallel(
    cast[ptr UncheckedArray[array[InputSize, float32]]](unsafeAddr inputs[0]),
    cast[ptr UncheckedArray[int]](addr engine.outputBuffer[0]),
    cast[ptr UncheckedArray[float32]](addr engine.confBuffer[0]),
    count
  )

  result.elapsedNs = (getMonoTime() - start).inNanoseconds
  result.throughput = count.float / (result.elapsedNs.float / 1e9)

  result.categories = engine.outputBuffer[0..<count]
  result.confidences = engine.confBuffer[0..<count]

# ========== ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ==========

when isMainModule:
  echo "=== Parallel Inference Engine ==="
  echo fmt"CPU Cores: {countProcessors()}"
  echo ""

  var engine: ParallelInferenceEngine
  engine.initParallelEngine()
  echo fmt"Initialized with {engine.numThreads} threads"
  echo fmt"Pre-allocated buffer: {engine.bufferSize} samples"
  echo ""

  # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
  let batchSize = 1_000_000
  var inputs = newSeq[array[InputSize, float32]](batchSize)
  for i in 0 ..< batchSize:
    for j in 0 ..< InputSize:
      inputs[i][j] = (i * InputSize + j).float32 / (batchSize * InputSize).float32

  # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
  echo "Warming up..."
  discard engine.inferBatchFast(inputs[0..9999])

  # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯1: ã‚«ãƒ†ã‚´ãƒªã®ã¿ï¼ˆæœ€é€Ÿç‰ˆï¼‰
  echo fmt"1. Category-only (Fast) - {batchSize} samples..."
  let resultFast = engine.inferBatchFast(inputs)
  echo fmt"   Throughput: {resultFast.throughput:.0f} samples/sec"
  echo fmt"   100k connections: {100_000.0 / resultFast.throughput * 1000:.2f} ms"
  echo ""

  # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯2: ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ç‰ˆï¼ˆã‚³ãƒ”ãƒ¼ãªã—ï¼‰
  echo fmt"2. Direct access (zero-copy) - {batchSize} samples..."
  let start2 = getMonoTime()
  let outputPtr = engine.inferBatchFastDirect(
    cast[ptr UncheckedArray[array[InputSize, float32]]](unsafeAddr inputs[0]),
    batchSize
  )
  let elapsed2 = (getMonoTime() - start2).inNanoseconds
  let throughput2 = batchSize.float / (elapsed2.float / 1e9)
  echo fmt"   Throughput: {throughput2:.0f} samples/sec"
  echo fmt"   100k connections: {100_000.0 / throughput2 * 1000:.2f} ms"
  echo ""

  # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯3: ä¿¡é ¼åº¦ä»˜ã
  echo fmt"3. With Confidence - {batchSize} samples..."
  let result = engine.inferBatch(inputs)
  echo fmt"   Throughput: {result.throughput:.0f} samples/sec"
  echo fmt"   100k connections: {100_000.0 / result.throughput * 1000:.2f} ms"
  echo ""

  # é€£ç¶šå®Ÿè¡Œãƒ†ã‚¹ãƒˆ
  echo "4. Continuous batch test (10 iterations, direct access)..."
  var totalThroughput = 0.0
  for iteration in 0..<10:
    let startIter = getMonoTime()
    discard engine.inferBatchFastDirect(
      cast[ptr UncheckedArray[array[InputSize, float32]]](unsafeAddr inputs[0]),
      batchSize
    )
    let elapsedIter = (getMonoTime() - startIter).inNanoseconds
    totalThroughput += batchSize.float / (elapsedIter.float / 1e9)
  let avgThroughput = totalThroughput / 10.0
  echo fmt"   Average Throughput: {avgThroughput:.0f} samples/sec"
  echo ""

  echo "=== Summary ==="
  echo fmt"Fast (with copy):     {resultFast.throughput:.0f} samples/sec"
  echo fmt"Direct (zero-copy):   {throughput2:.0f} samples/sec"
  echo fmt"Full (with conf):     {result.throughput:.0f} samples/sec"
  echo fmt"Average (10 runs):    {avgThroughput:.0f} samples/sec"

  # ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³è¡¨ç¤º
  if avgThroughput >= 20_000_000:
    echo ""
    echo "ğŸš€ğŸš€ğŸš€ 20M+ samples/sec achieved! ğŸš€ğŸš€ğŸš€"
  elif avgThroughput >= 15_000_000:
    echo ""
    echo "ğŸš€ğŸš€ 15M+ samples/sec achieved! ğŸš€ğŸš€"
  elif avgThroughput >= 10_000_000:
    echo ""
    echo "ğŸš€ 10M+ samples/sec achieved! ğŸš€"
