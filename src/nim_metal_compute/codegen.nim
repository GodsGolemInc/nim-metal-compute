## Code Generator
## ネットワーク定義からMetal/Nimコードを自動生成
##
## 生成対象:
##   - Metal Compute Shader (推論 + 学習)
##   - Nim CPU実装 (推論 + 学習)
##   - Objective-C ラッパー

import std/[strformat, strutils, os]
import network_spec

type
  CodeGenTarget* = enum
    tgtMetal = "metal"
    tgtNimCPU = "nim_cpu"
    tgtObjCWrapper = "objc_wrapper"
    tgtAll = "all"

  CodeGenOptions* = object
    target*: CodeGenTarget
    outputDir*: string
    includeTraining*: bool
    optimizeForSize*: bool
    addComments*: bool

proc defaultOptions*(): CodeGenOptions =
  CodeGenOptions(
    target: tgtAll,
    outputDir: "generated",
    includeTraining: true,
    optimizeForSize: false,
    addComments: true
  )

# ========== Metal シェーダー生成 ==========

proc generateMetalActivation(act: ActivationType): string =
  case act
  of actReLU: "relu(x)"
  of actSigmoid: "sigmoid(x)"
  of actTanh: "tanh(x)"
  of actLeakyReLU: "leaky_relu(x)"
  of actSoftmax: "x"  # Softmaxは後で適用
  of actNone: "x"

proc generateMetalKernel*(spec: NetworkSpec, opts: CodeGenOptions = defaultOptions()): string =
  ## Metal Compute Shaderを生成
  let name = spec.name.toLowerAscii.replace(" ", "_")

  result = """
//
// Auto-generated Metal Shader
// Network: {name}
// Generated by nim-metal-compute
//
// DO NOT EDIT - Regenerate from network specification
//

#include <metal_stdlib>
using namespace metal;

""".replace("{name}", spec.name)

  # 定数定義
  result.add "// Network dimensions\n"
  result.add fmt"constant int INPUT_SIZE = {spec.inputSize()};" & "\n"
  result.add fmt"constant int OUTPUT_SIZE = {spec.outputSize()};" & "\n"

  for i, layer in spec.layers:
    result.add fmt"constant int LAYER{i}_SIZE = {layer.outputSize};" & "\n"

  result.add "\n"

  # 活性化関数
  result.add """
// Activation functions
inline float relu(float x) { return max(0.0f, x); }
inline float sigmoid(float x) { return 1.0f / (1.0f + exp(-x)); }
inline float leaky_relu(float x) { return x > 0.0f ? x : 0.01f * x; }

inline void softmax(thread float* values, int size) {
    float maxVal = values[0];
    for (int i = 1; i < size; i++) maxVal = max(maxVal, values[i]);
    float sum = 0.0f;
    for (int i = 0; i < size; i++) { values[i] = exp(values[i] - maxVal); sum += values[i]; }
    for (int i = 0; i < size; i++) values[i] /= sum;
}

"""

  # 重み構造体
  result.add "// Weights structure\n"
  result.add "struct NetworkWeights {\n"

  for i, layer in spec.layers:
    if layer.kind == lkDense:
      result.add fmt"    float layer{i}_weights[{layer.inputSize} * {layer.outputSize}];" & "\n"
      if layer.useBias:
        result.add fmt"    float layer{i}_bias[{layer.outputSize}];" & "\n"

  result.add "};\n\n"

  # 推論結果構造体
  result.add fmt"""
// Inference result
struct InferenceResult {{
    int category;
    float confidence;
    float probabilities[{spec.outputSize()}];
}};

"""

  # 推論カーネル
  result.add fmt"// Inference kernel\n"
  result.add fmt"kernel void {name}_inference(" & "\n"
  result.add "    device const float* input [[buffer(0)]],\n"
  result.add "    device const NetworkWeights* weights [[buffer(1)]],\n"
  result.add "    device InferenceResult* results [[buffer(2)]],\n"
  result.add "    uint gid [[thread_position_in_grid]]\n"
  result.add ") {\n"
  result.add fmt"    int offset = gid * INPUT_SIZE;" & "\n\n"

  # 各層の計算
  var prevSize = spec.inputSize()
  var prevVar = "input"

  for i, layer in spec.layers:
    let curVar = fmt"layer{i}"

    if opts.addComments:
      result.add fmt"    // Layer {i}: {layer.name} ({layer.kind})\n"

    if layer.kind == lkDense:
      result.add fmt"    float {curVar}[{layer.outputSize}];" & "\n"
      result.add fmt"    for (int o = 0; o < {layer.outputSize}; o++) {{" & "\n"

      if layer.useBias:
        result.add fmt"        float sum = weights->layer{i}_bias[o];" & "\n"
      else:
        result.add "        float sum = 0.0f;\n"

      result.add fmt"        for (int j = 0; j < {prevSize}; j++) {{" & "\n"

      if i == 0:
        result.add fmt"            sum += {prevVar}[offset + j] * weights->layer{i}_weights[j * {layer.outputSize} + o];" & "\n"
      else:
        result.add fmt"            sum += {prevVar}[j] * weights->layer{i}_weights[j * {layer.outputSize} + o];" & "\n"

      result.add "        }\n"

      # 活性化関数
      let actCode = case layer.activation
        of actReLU: "relu(sum)"
        of actSigmoid: "sigmoid(sum)"
        of actLeakyReLU: "leaky_relu(sum)"
        else: "sum"

      result.add fmt"        {curVar}[o] = {actCode};" & "\n"
      result.add "    }\n\n"

    prevSize = layer.outputSize
    prevVar = curVar

  # Softmax (最後の層がSoftmaxの場合)
  let lastLayer = spec.layers[^1]
  let lastVar = fmt"layer{spec.layers.len - 1}"
  if lastLayer.activation == actSoftmax:
    result.add fmt"    // Apply softmax\n"
    result.add fmt"    softmax({lastVar}, {lastLayer.outputSize});" & "\n\n"

  # 結果格納
  result.add "    // Find best category and store results\n"
  result.add "    int bestIdx = 0;\n"
  result.add fmt"    float bestVal = {lastVar}[0];" & "\n"
  result.add fmt"    for (int i = 1; i < {lastLayer.outputSize}; i++) {{" & "\n"
  result.add fmt"        if ({lastVar}[i] > bestVal) {{ bestVal = {lastVar}[i]; bestIdx = i; }}" & "\n"
  result.add "    }\n\n"
  result.add "    results[gid].category = bestIdx;\n"
  result.add "    results[gid].confidence = bestVal;\n"
  result.add fmt"    for (int i = 0; i < {lastLayer.outputSize}; i++) results[gid].probabilities[i] = {lastVar}[i];" & "\n"
  result.add "}\n"

  # 学習カーネル (オプション)
  if opts.includeTraining:
    result.add "\n"
    result.add "// ========== Training Kernels ==========\n\n"

    # 勾配構造体
    result.add "struct NetworkGradients {\n"
    for i, layer in spec.layers:
      if layer.kind == lkDense:
        result.add fmt"    float layer{i}_weights[{layer.inputSize} * {layer.outputSize}];" & "\n"
        if layer.useBias:
          result.add fmt"    float layer{i}_bias[{layer.outputSize}];" & "\n"
    result.add "};\n\n"

    # ForwardCache
    result.add "struct ForwardCache {\n"
    for i, layer in spec.layers:
      result.add fmt"    float layer{i}[{layer.outputSize}];" & "\n"
      result.add fmt"    float layer{i}_pre[{layer.outputSize}];" & "\n"
    result.add "};\n\n"

    result.add "struct TrainingParams {\n"
    result.add "    float learning_rate;\n"
    result.add "    float momentum;\n"
    result.add "    float weight_decay;\n"
    result.add "    int batch_size;\n"
    result.add "};\n\n"

    # ReLU導関数
    result.add "inline float relu_derivative(float x) { return x > 0.0f ? 1.0f : 0.0f; }\n\n"

    # Forward pass (学習用)
    result.add fmt"kernel void {name}_forward_training(" & "\n"
    result.add "    device const float* input [[buffer(0)]],\n"
    result.add "    device const NetworkWeights* weights [[buffer(1)]],\n"
    result.add "    device ForwardCache* cache [[buffer(2)]],\n"
    result.add "    device float* predictions [[buffer(3)]],\n"
    result.add "    uint gid [[thread_position_in_grid]]\n"
    result.add ") {\n"
    result.add "    int offset = gid * INPUT_SIZE;\n"
    result.add "    int predOffset = gid * OUTPUT_SIZE;\n\n"

    prevSize = spec.inputSize()
    prevVar = "input"

    for i, layer in spec.layers:
      if layer.kind == lkDense:
        let prevIdx = i - 1
        result.add fmt"    for (int o = 0; o < {layer.outputSize}; o++) {{" & "\n"
        if layer.useBias:
          result.add fmt"        float sum = weights->layer{i}_bias[o];" & "\n"
        else:
          result.add "        float sum = 0.0f;\n"

        if i == 0:
          result.add fmt"        for (int j = 0; j < {prevSize}; j++) sum += {prevVar}[offset + j] * weights->layer{i}_weights[j * {layer.outputSize} + o];" & "\n"
        else:
          result.add fmt"        for (int j = 0; j < {prevSize}; j++) sum += cache[gid].layer{prevIdx}[j] * weights->layer{i}_weights[j * {layer.outputSize} + o];" & "\n"

        result.add fmt"        cache[gid].layer{i}_pre[o] = sum;" & "\n"

        if layer.activation == actReLU:
          result.add fmt"        cache[gid].layer{i}[o] = relu(sum);" & "\n"
        else:
          result.add fmt"        cache[gid].layer{i}[o] = sum;" & "\n"

        result.add "    }\n\n"

      prevSize = layer.outputSize

    # Softmax
    if lastLayer.activation == actSoftmax:
      result.add fmt"    softmax(cache[gid].layer{spec.layers.len - 1}, OUTPUT_SIZE);" & "\n"

    result.add fmt"    for (int i = 0; i < OUTPUT_SIZE; i++) predictions[predOffset + i] = cache[gid].layer{spec.layers.len - 1}[i];" & "\n"
    result.add "}\n\n"

    # Backward pass
    result.add fmt"kernel void {name}_backward(" & "\n"
    result.add "    device const float* input [[buffer(0)]],\n"
    result.add "    device const NetworkWeights* weights [[buffer(1)]],\n"
    result.add "    device const ForwardCache* cache [[buffer(2)]],\n"
    result.add "    device const int* labels [[buffer(3)]],\n"
    result.add "    device NetworkGradients* gradients [[buffer(4)]],\n"
    result.add "    device float* loss [[buffer(5)]],\n"
    result.add "    uint gid [[thread_position_in_grid]]\n"
    result.add ") {\n"
    result.add "    int offset = gid * INPUT_SIZE;\n"
    result.add "    int label = labels[gid];\n\n"

    # Cross-entropy loss
    result.add fmt"    loss[gid] = -log(max(cache[gid].layer{spec.layers.len - 1}[label], 1e-7f));" & "\n\n"

    # Output layer delta
    result.add fmt"    float delta_output[OUTPUT_SIZE];" & "\n"
    result.add "    for (int o = 0; o < OUTPUT_SIZE; o++) {\n"
    result.add fmt"        delta_output[o] = cache[gid].layer{spec.layers.len - 1}[o] - (o == label ? 1.0f : 0.0f);" & "\n"
    result.add "    }\n\n"

    # 勾配計算 (サンプルごと)
    for i in countdown(spec.layers.len - 1, 0):
      let layer = spec.layers[i]
      let prevIdx = i - 1
      let nextIdx = i + 1
      if layer.kind == lkDense:
        if i == spec.layers.len - 1:
          # 出力層
          if i > 0:
            result.add fmt"    for (int h = 0; h < {spec.layers[prevIdx].outputSize}; h++) {{" & "\n"
            result.add fmt"        for (int o = 0; o < {layer.outputSize}; o++) {{" & "\n"
            result.add fmt"            gradients[gid].layer{i}_weights[h * {layer.outputSize} + o] = cache[gid].layer{prevIdx}[h] * delta_output[o];" & "\n"
            result.add "        }\n"
            result.add "    }\n"
          else:
            result.add fmt"    for (int h = 0; h < INPUT_SIZE; h++) {{" & "\n"
            result.add fmt"        for (int o = 0; o < {layer.outputSize}; o++) {{" & "\n"
            result.add fmt"            gradients[gid].layer{i}_weights[h * {layer.outputSize} + o] = input[offset + h] * delta_output[o];" & "\n"
            result.add "        }\n"
            result.add "    }\n"

          if layer.useBias:
            result.add fmt"    for (int o = 0; o < {layer.outputSize}; o++) gradients[gid].layer{i}_bias[o] = delta_output[o];" & "\n"
          result.add "\n"
        else:
          # 隠れ層
          result.add fmt"    float delta_layer{i}[{layer.outputSize}];" & "\n"
          result.add fmt"    for (int h = 0; h < {layer.outputSize}; h++) {{" & "\n"
          result.add "        float sum = 0.0f;\n"

          let nextLayer = spec.layers[nextIdx]
          if i == spec.layers.len - 2:
            result.add fmt"        for (int o = 0; o < {nextLayer.outputSize}; o++) sum += delta_output[o] * weights->layer{nextIdx}_weights[h * {nextLayer.outputSize} + o];" & "\n"
          else:
            result.add fmt"        for (int o = 0; o < {nextLayer.outputSize}; o++) sum += delta_layer{nextIdx}[o] * weights->layer{nextIdx}_weights[h * {nextLayer.outputSize} + o];" & "\n"

          result.add fmt"        delta_layer{i}[h] = sum * relu_derivative(cache[gid].layer{i}_pre[h]);" & "\n"
          result.add "    }\n\n"

          if i > 0:
            result.add fmt"    for (int j = 0; j < {spec.layers[prevIdx].outputSize}; j++) {{" & "\n"
          else:
            result.add fmt"    for (int j = 0; j < INPUT_SIZE; j++) {{" & "\n"

          result.add fmt"        for (int h = 0; h < {layer.outputSize}; h++) {{" & "\n"

          if i > 0:
            result.add fmt"            gradients[gid].layer{i}_weights[j * {layer.outputSize} + h] = cache[gid].layer{prevIdx}[j] * delta_layer{i}[h];" & "\n"
          else:
            result.add fmt"            gradients[gid].layer{i}_weights[j * {layer.outputSize} + h] = input[offset + j] * delta_layer{i}[h];" & "\n"

          result.add "        }\n"
          result.add "    }\n"

          if layer.useBias:
            result.add fmt"    for (int h = 0; h < {layer.outputSize}; h++) gradients[gid].layer{i}_bias[h] = delta_layer{i}[h];" & "\n"
          result.add "\n"

    result.add "}\n"

# ========== Nim CPU コード生成 ==========

proc generateNimCPU*(spec: NetworkSpec, opts: CodeGenOptions = defaultOptions()): string =
  ## Nim CPU実装を生成
  let name = spec.name
  let nameLower = name.toLowerAscii.replace(" ", "_")

  result = fmt"""
## Auto-generated CPU implementation for {name}
## Generated by nim-metal-compute
##
## DO NOT EDIT - Regenerate from network specification

import std/[math, sequtils]

const
  INPUT_SIZE* = {spec.inputSize()}
  OUTPUT_SIZE* = {spec.outputSize()}

"""

  # 層サイズ
  for i, layer in spec.layers:
    result.add fmt"  LAYER{i}_SIZE* = {layer.outputSize}" & "\n"

  result.add "\n"

  # 重み構造体
  result.add "type\n"
  result.add fmt"  {name}Weights* = object" & "\n"

  for i, layer in spec.layers:
    if layer.kind == lkDense:
      result.add fmt"    layer{i}Weights*: array[{layer.inputSize * layer.outputSize}, float32]" & "\n"
      if layer.useBias:
        result.add fmt"    layer{i}Bias*: array[{layer.outputSize}, float32]" & "\n"

  result.add "\n"

  result.add fmt"  {name}Result* = object" & "\n"
  result.add "    category*: int\n"
  result.add "    confidence*: float32\n"
  result.add fmt"    probabilities*: array[OUTPUT_SIZE, float32]" & "\n"

  result.add "\n"

  # 活性化関数
  result.add """
# Activation functions
proc relu(x: float32): float32 {.inline.} = max(0.0f32, x)
proc sigmoid(x: float32): float32 {.inline.} = 1.0f32 / (1.0f32 + exp(-x))
proc leakyRelu(x: float32): float32 {.inline.} = (if x > 0: x else: 0.01f32 * x)

proc softmax(values: var openArray[float32]) =
  var maxVal = values[0]
  for v in values: maxVal = max(maxVal, v)
  var sum = 0.0f32
  for i in 0..<values.len:
    values[i] = exp(values[i] - maxVal)
    sum += values[i]
  for i in 0..<values.len:
    values[i] /= sum

"""

  # 推論関数
  result.add fmt"proc infer*(weights: {name}Weights, input: array[INPUT_SIZE, float32]): {name}Result =" & "\n"

  var prevSize = spec.inputSize()
  var prevVar = "input"

  for i, layer in spec.layers:
    let curVar = fmt"layer{i}"

    if layer.kind == lkDense:
      result.add fmt"  # Layer {i}: {layer.name}" & "\n"
      result.add fmt"  var {curVar}: array[{layer.outputSize}, float32]" & "\n"
      result.add fmt"  for o in 0..<{layer.outputSize}:" & "\n"

      if layer.useBias:
        result.add fmt"    var sum = weights.layer{i}Bias[o]" & "\n"
      else:
        result.add "    var sum = 0.0f32\n"

      result.add fmt"    for j in 0..<{prevSize}:" & "\n"
      result.add fmt"      sum += {prevVar}[j] * weights.layer{i}Weights[j * {layer.outputSize} + o]" & "\n"

      let actCode = case layer.activation
        of actReLU: "relu(sum)"
        of actSigmoid: "sigmoid(sum)"
        of actLeakyReLU: "leakyRelu(sum)"
        else: "sum"

      result.add fmt"    {curVar}[o] = {actCode}" & "\n"
      result.add "\n"

    prevSize = layer.outputSize
    prevVar = curVar

  # Softmax
  let lastVar = fmt"layer{spec.layers.len - 1}"
  if spec.layers[^1].activation == actSoftmax:
    result.add fmt"  softmax({lastVar})" & "\n\n"

  # 結果
  result.add "  # Find best category\n"
  result.add "  var bestIdx = 0\n"
  result.add fmt"  var bestVal = {lastVar}[0]" & "\n"
  result.add fmt"  for i in 1..<OUTPUT_SIZE:" & "\n"
  result.add fmt"    if {lastVar}[i] > bestVal:" & "\n"
  result.add fmt"      bestVal = {lastVar}[i]" & "\n"
  result.add "      bestIdx = i\n\n"

  result.add "  result.category = bestIdx\n"
  result.add "  result.confidence = bestVal\n"
  result.add fmt"  result.probabilities = {lastVar}" & "\n"

  # バッチ推論
  result.add "\n"
  result.add fmt"proc inferBatch*(weights: {name}Weights, inputs: seq[array[INPUT_SIZE, float32]]): seq[{name}Result] =" & "\n"
  result.add "  result = newSeq[" & name & "Result](inputs.len)\n"
  result.add "  for i, input in inputs:\n"
  result.add "    result[i] = weights.infer(input)\n"

# ========== 保存・書き出し ==========

proc generate*(spec: NetworkSpec, opts: CodeGenOptions = defaultOptions()) =
  ## ネットワーク定義からコードを生成してファイルに保存
  createDir(opts.outputDir)

  let baseName = spec.name.toLowerAscii.replace(" ", "_")

  if opts.target in {tgtMetal, tgtAll}:
    let metalCode = generateMetalKernel(spec, opts)
    let metalPath = opts.outputDir / baseName & ".metal"
    writeFile(metalPath, metalCode)
    echo fmt"Generated: {metalPath}"

  if opts.target in {tgtNimCPU, tgtAll}:
    let nimCode = generateNimCPU(spec, opts)
    let nimPath = opts.outputDir / baseName & "_cpu.nim"
    writeFile(nimPath, nimCode)
    echo fmt"Generated: {nimPath}"

# ========== テスト ==========

when isMainModule:
  echo "=== Code Generator Test ==="

  let spec = koanClassifierSpec()

  echo "\n--- Metal Shader ---"
  echo generateMetalKernel(spec)

  echo "\n--- Nim CPU ---"
  echo generateNimCPU(spec)

  # ファイル生成テスト
  var opts = defaultOptions()
  opts.outputDir = "test_generated"
  spec.generate(opts)

  echo "\n✅ Code generation test passed!"
